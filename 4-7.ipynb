{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第四章：基于概率论的分类方法：朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "贝叶斯分类是一类分类算法的总称，这类算法均以贝叶斯定理为基础，故统称为贝叶斯分类。本章首先介绍贝叶斯分类算法的基础——贝叶斯定理。最后，我们通过实例来讨论贝叶斯分类的中最简单的一种: 朴素贝叶斯分类。\n",
    "\n",
    "所谓朴素贝叶斯，就是认为属性都是互相独立的，并且权重都是一样的。\n",
    "\n",
    "朴素贝叶斯算法特点\n",
    "- 优点：数据较少情况仍然有效，可以处理多类别问题\n",
    "- 缺点：对输入数据的准备方式比较敏感\n",
    "- 适用数据类型：标称型数据\n",
    "\n",
    "开发流程\n",
    "- 收集数据: 可以使用任何方法\n",
    "- 准备数据: 从文本中构建词向量\n",
    "- 分析数据: 检查词条确保解析的正确性\n",
    "- 训练算法: 从词向量计算概率\n",
    "- 测试算法: 根据现实情况修改分类器\n",
    "- 使用算法: 对社区留言板言论进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.屏蔽侮辱性词汇言论"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "贝叶斯公式\n",
    "p(xy)=p(x|y)p(y)=p(y|x)p(x)\n",
    "p(x|y)=p(y|x)p(x)/p(y)\n",
    "\"\"\"\n",
    "\n",
    "# ------项目案例1: 屏蔽社区留言板的侮辱性言论------\n",
    "\n",
    "\n",
    "def load_data_set():\n",
    "    \"\"\"\n",
    "    创建数据集,都是假的 fake data set \n",
    "    :return: 单词列表posting_list, 所属类别class_vec\n",
    "    \"\"\"\n",
    "    posting_list = [\n",
    "        ['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],\n",
    "        ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],\n",
    "        ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],\n",
    "        ['stop', 'posting', 'stupid', 'worthless', 'gar e'],\n",
    "        ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],\n",
    "        ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']]\n",
    "    class_vec = [0, 1, 0, 1, 0, 1]  # 1 is 侮辱性的文字, 0 is not\n",
    "    return posting_list, class_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocab_list(data_set):\n",
    "    \"\"\"\n",
    "    获取所有单词的集合\n",
    "    :param data_set: 数据集\n",
    "    :return: 所有单词的集合(即不含重复元素的单词列表)\n",
    "    \"\"\"\n",
    "    vocab_set = set()  # create empty set\n",
    "    for item in data_set:\n",
    "        # | 求两个集合的并集\n",
    "        vocab_set = vocab_set | set(item)\n",
    "    return list(vocab_set)\n",
    "\n",
    "\n",
    "def set_of_words2vec(vocab_list, input_set):\n",
    "    \"\"\"\n",
    "    遍历查看该单词是否出现，出现该单词则将该单词置1\n",
    "    :param vocab_list: 所有单词集合列表\n",
    "    :param input_set: 输入数据集\n",
    "    :return: 匹配列表[0,1,0,1...]，其中 1与0 表示词汇表中的单词是否出现在输入的数据集中\n",
    "    \"\"\"\n",
    "    # 创建一个和词汇表等长的向量，并将其元素都设置为0\n",
    "    result = [0] * len(vocab_list)\n",
    "    # 遍历文档中的所有单词，如果出现了词汇表中的单词，则将输出的文档向量中的对应值设为1\n",
    "    for word in input_set:\n",
    "        if word in vocab_list:\n",
    "            result[vocab_list.index(word)] = 1\n",
    "        else:\n",
    "            # 这个后面应该注释掉，因为对你没什么用，这只是为了辅助调试的\n",
    "            # print('the word: {} is not in my vocabulary'.format(word))\n",
    "            pass\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
